{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imAdityaSatya/DocuChat/blob/main/DocuChat_(version_0).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bvqxhSnPhKH"
      },
      "source": [
        "**DocuChat** : QnA ChatBot version-0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pn1PGWnXPr8"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "# !pip install pypdf transformers torch\n",
        "!pip install pypdf transformers torch sentence-transformers faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7eB1NmphgIk"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from pypdf import PdfReader\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "# Greeting detection setup\n",
        "GREETINGS_IN = {\"hi\", \"hello\", \"hey\", \"good morning\", \"good evening\", \"greetings\"}\n",
        "GREETINGS_OUT = [\"Hello!\", \"Hi there!\", \"Hey! How can I help?\"]\n",
        "\n",
        "def check_greeting(text: str) -> str:\n",
        "    return random.choice(GREETINGS_OUT) if text.lower() in GREETINGS_IN else \"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6_Avmr_hjWv"
      },
      "outputs": [],
      "source": [
        "# Functions for PDF Text Extraction & Chunking\n",
        "\n",
        "def extract_pdf_text(path: str) -> str:\n",
        "    reader = PdfReader(path)\n",
        "    return \"\\n\".join(page.extract_text() or \"\" for page in reader.pages)\n",
        "\n",
        "def chunk_text(text: str, max_len: int = 400, stride: int = 50) -> list[str]:\n",
        "    words = text.split()\n",
        "    return [\n",
        "        \" \".join(words[i : i + max_len])\n",
        "        for i in range(0, len(words), max_len - stride)\n",
        "    ]\n",
        "\n",
        "# Upload PDF file\n",
        "uploaded = files.upload()\n",
        "pdf_path = next(iter(uploaded.keys()))\n",
        "\n",
        "# Extract and chunk text\n",
        "full_text = extract_pdf_text(pdf_path)\n",
        "contexts = chunk_text(full_text)\n",
        "print(f\"Extracted {len(contexts)} chunks from your PDF\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xPKdV_ThsCm"
      },
      "outputs": [],
      "source": [
        "# Load the embedding model\n",
        "embedder = SentenceTransformer(\"all-mpnet-base-v2\")\n",
        "\n",
        "# Embed the contexts\n",
        "embeddings = embedder.encode(contexts, convert_to_numpy=True, show_progress_bar=True)\n",
        "\n",
        "# Normalize and Build FAISS Index for Retrieval\n",
        "faiss.normalize_L2(embeddings)\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatIP(dimension)\n",
        "index.add(embeddings)\n",
        "print(\"FAISS index built successfully\")\n",
        "\n",
        "\n",
        "# Initialize the QnA Pipeline\n",
        "qa_pipeline = pipeline(\n",
        "    \"question-answering\",\n",
        "    model=\"deepset/roberta-base-squad2\",\n",
        "    tokenizer=\"deepset/roberta-base-squad2\"\n",
        ")\n",
        "print(\"QnA Pipeline Initialized\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wf5ZPvf2jwz2"
      },
      "outputs": [],
      "source": [
        "# Interactive Chatbot\n",
        "print(\"ðŸ“„DocuChatðŸ¤– is ready! \\nType in your question and hit Enter\\tType 'exit' or 'quit' to stop\\n\")\n",
        "\n",
        "# Some querry triggers\n",
        "INTRO_QUERIES = {\"who are you\", \"what's your name\", \"whats your name\", \"what can you do\", \"are you a bot\", \"are you a chatbot\", \"introduce yourself\"}\n",
        "CREATOR_QUERIES = {\"who built you\", \"who created you\", \"who made you\", \"who's your creator\", \"who is your creator\"}\n",
        "GRATITUDE_QUERIES = {\"thanks\", \"thank you\", \"good\", \"great\", \"wow\", \"awesome\", \"cool\", \"nice\", \"got it\", \"ok\", \"okay\"}\n",
        "GREET_QUERIES = {\"how are you\", \"how are you doing\", \"how are you feeling\"}\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \").strip()\n",
        "    # Cleaned user input : Convert to lowercase and ignore special chars (?, !)\n",
        "    cleaned_input = user_input.lower().replace(\"?\", \"\").replace(\"!\", \"\")\n",
        "\n",
        "    # Exit Commands\n",
        "    if cleaned_input in {\"exit\", \"quit\", \"bye\", \"goodbye\"}:\n",
        "        print(\"Bot: Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Intro query handling\n",
        "    if cleaned_input in INTRO_QUERIES:\n",
        "        print(\"Bot: I am DocuChat, a QnA chatbot that can answer questions based on any PDF you upload.\")\n",
        "        continue\n",
        "\n",
        "    # Creator query handling\n",
        "    if cleaned_input in CREATOR_QUERIES:\n",
        "        print(\"Bot: I was created by Aditya Satya :) \")\n",
        "        continue\n",
        "\n",
        "    # Gratitude query handling\n",
        "    if cleaned_input in GRATITUDE_QUERIES:\n",
        "        print(\"Bot: Happy to help! \\n     Let me know if there's anything else I can help you with. \\n\")\n",
        "        continue\n",
        "\n",
        "    # Greet query handling\n",
        "    if cleaned_input in GREET_QUERIES:\n",
        "        print(\"Bot: I'm doing great, thanks for asking. \\n     How may I help you?\\n\")\n",
        "        continue\n",
        "\n",
        "    # Handle greetings\n",
        "    greet = check_greeting(cleaned_input)\n",
        "    if greet:\n",
        "        print(f\"Bot: {greet}\")\n",
        "        continue\n",
        "\n",
        "    # Handle the empty input\n",
        "    if not user_input:\n",
        "        print(\"Bot: Your input is empty. Please ask a question.\")\n",
        "        continue\n",
        "\n",
        "\n",
        "    # Encode query and retrieve top-k contexts\n",
        "    q_emb = embedder.encode(user_input, convert_to_numpy=True)\n",
        "    faiss.normalize_L2(q_emb.reshape(1, -1))\n",
        "    D, I = index.search(q_emb.reshape(1, -1), k=3)  # retrieve top-3\n",
        "\n",
        "    # Run QA on retrieved chunks\n",
        "    best = {\"score\": 0.0, \"answer\": \"Sorry, this is beyond the scope of abilities.\"}\n",
        "    for idx in I[0]:\n",
        "        result = qa_pipeline(question=user_input, context=contexts[idx])\n",
        "        if result[\"score\"] > best[\"score\"]:\n",
        "            best = result\n",
        "\n",
        "    # Confidence threshold\n",
        "    if best[\"score\"] < 0.25:\n",
        "        print(\"Bot: Sorry, I'm not really sure about that.\")\n",
        "    else:\n",
        "        print(f\"Bot: {best['answer']}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONjKmR6emYDnqqzASUQhXN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}